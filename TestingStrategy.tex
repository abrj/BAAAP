\section{Testing Strategy}
Proper and thorough is an essential part of a software project, insuring a way to prove the validity of functions and features, and enabling quality assurance, so that the product owner knows he gets what was agreed upon. \

It is though not just something you do, or a team simply applies. There is no way that fits every kind of software project, so an analysis of what would suit the project best is always in place. For the RentIt project we considered using a simplified version of the software development practise know as 'Continuous Integration' [http://www.martinfowler.com/articles/continuousIntegration.html], and its way of testing.

This practise or tool, being a part of the Extreme Programming thought, focuses on iterating many times a day, trying to enforce methods to make the process of development faster, and more precise. This is done by having developers committing to a single source repository many times daily, trying to evade a 'merge-hell'. Further more, each commit should be object to a full build and run of all unit-tests, to insure as few errors as possible in the source repository. This can in practise be done on a build server, that builds and tests with every commit.

As we are a small development team, some of the practises of XP are to harsh in comparison to the benefit we would get from it. The thing we would try to utilize, is the automated builds and test for every commit. This would fit well with one our other considerations, of writing the unit-tests along with, and even before, the code itself. This would give us thorough testing of every developed sub-system from the get go, and that no piece of code would be it was committed to our source repository, without it having been tested. As we used a Microsoft Team Foundation Server as our version control software and shared repository, we could utilized the built-in tools for this to apply these Continuous Integration principles to our project.

We did not end up applying this, but the thoughts and methods affected how we ended up doing our testing. We held on to making our unit-tests as early on as possible, making sure everything is tested before committed. But it proved to much work compared to the benefits to implement a automated build server with testing. Our approach still gave us beneficial testing from an early point in the implementation process.\

But what should be tested, is a different matter. A popular belief is that you can never test to much, but no one has infinitely amounts of time for this. Therefore, again, an analysis should be done to get an understanding of what is important to test. As said earlier, testing is a big part of quality assurance and the validation of features, and for us this is where it is most useful. Because of this we have chosen to focus our testing around our use-cases, as these have given rise to many of our functional requirement. We have stated how each use-case and the functions it uses is validated by tests in the appendix on page \pageref{TestAppendix}

The other part of our requirements are the non-functional ones, but these don't have as much importances in a small, self-run project like ours. Even thou these are easier measurable, our estimates are not to well grounded, and we have not tested for these. The non-functional requirements can be found in our Factor Table on page \pageref{FactorTable}.

